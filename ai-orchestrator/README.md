# ğŸ¤– AI Orchestrator - Asistente Inteligente para Sistema Chifless

## Â¿QuÃ© es esto?

El **AI Orchestrator** es el cerebro inteligente del Sistema Chifless. Es un servicio que permite a los usuarios interactuar con el sistema de gestiÃ³n de pedidos de chifles usando lenguaje natural, como si estuvieran hablando con una persona.

En lugar de navegar por menÃºs o llenar formularios, puedes simplemente escribir cosas como:
- *"Â¿QuÃ© productos tienen disponibles?"*
- *"Quiero hacer un pedido de 10 bolsas de chifles de sal"*
- *"Â¿CÃ³mo va mi pedido #123?"*
- *"MuÃ©strame las ventas de esta semana"*

---

## ğŸ¯ Â¿CÃ³mo funciona? (ExplicaciÃ³n simple)

Imagina que tienes un asistente muy inteligente que puede:
1. **Entender lo que escribes** - Usa inteligencia artificial para comprender tus mensajes
2. **Decidir quÃ© hacer** - Determina si necesita consultar productos, crear pedidos, etc.
3. **Ejecutar acciones** - Se conecta con el sistema real para hacer las cosas
4. **Responderte** - Te explica quÃ© hizo y quÃ© encontrÃ³

### El flujo es asÃ­:

```
Usuario escribe: "Quiero ver los productos disponibles"
         â†“
    [AI Orchestrator]
         â†“
    El LLM (IA) entiende que quieres ver productos
         â†“
    Decide usar la herramienta "consultar_productos"
         â†“
    Llama al API Rest para obtener los productos
         â†“
    Recibe los datos y los formatea bonito
         â†“
Usuario recibe: "Tenemos estos productos: Chifles de Sal ($5)..."
```

---

## ğŸ§© Los 3 Componentes Principales

### 1. ğŸ’¬ MÃ³dulo de Chat (`/src/chat/`)

Este es el **punto de entrada**. AquÃ­ llegan todos los mensajes de los usuarios.

**Â¿QuÃ© hace?**
- Recibe los mensajes a travÃ©s del endpoint `/api/chat/message`
- Mantiene el historial de conversaciÃ³n por sesiÃ³n (recuerda lo que hablaste antes)
- Coordina todo el proceso de respuesta
- Guarda logs de todas las interacciones para auditorÃ­a

**Endpoints disponibles:**
| MÃ©todo | Ruta | DescripciÃ³n |
|--------|------|-------------|
| POST | `/api/chat/message` | Enviar un mensaje al asistente |
| GET | `/api/chat/session/:id/history` | Ver el historial de una conversaciÃ³n |
| DELETE | `/api/chat/session/:id` | Limpiar una conversaciÃ³n |
| GET | `/api/chat/models` | Ver modelos de IA disponibles |
| PUT | `/api/chat/provider` | Cambiar el proveedor de IA |
| GET | `/api/chat/logs` | Ver logs de interacciones |

---

### 2. ğŸ§  MÃ³dulo LLM (`/src/llm/`)

Este es el **cerebro**. AquÃ­ es donde vive la inteligencia artificial.

**Â¿QuÃ© hace?**
- Se conecta con diferentes proveedores de IA (puedes elegir cuÃ¡l usar)
- EnvÃ­a los mensajes al modelo de IA elegido
- Recibe las respuestas y detecta si la IA quiere usar herramientas
- Maneja errores y lÃ­mites de uso de las APIs

**Proveedores disponibles:**

| Proveedor | Modelo por defecto | Notas |
|-----------|-------------------|-------|
| ğŸŸ¢ **Groq** | llama-3.3-70b-versatile | Â¡GRATIS! Muy rÃ¡pido |
| ğŸ”µ **Google Gemini** | gemini-2.0-flash | Muy capaz, soporta imÃ¡genes |
| âš« **xAI Grok** | grok-2-latest | Modelo de X/Twitter |
| ğŸŸ¡ **OpenAI** | gpt-4o-mini | El clÃ¡sico ChatGPT |

**Â¿CÃ³mo cambiar de proveedor?**

Puedes cambiar en cualquier momento enviando:
```bash
PUT /api/chat/provider
{ "provider": "gemini" }  # o "groq", "grok", "openai"
```

---

### 3. ğŸ› ï¸ MÃ³dulo MCP Tools (`/src/mcp/`)

Estas son las **manos** del asistente. Las herramientas que puede usar para hacer cosas reales.

**Â¿QuÃ© hace?**
- Define las acciones que el asistente puede realizar
- Ejecuta las llamadas a la API Rest del sistema
- EnvÃ­a notificaciones por WebSocket cuando crea pedidos

**Herramientas disponibles:**

| Herramienta | DescripciÃ³n | Ejemplo de uso |
|-------------|-------------|----------------|
| `consultar_productos` | Ve todos los productos y precios | "Â¿QuÃ© chifles tienen?" |
| `estado_pedido` | Consulta el estado de un pedido | "Â¿CÃ³mo va mi pedido #15?" |
| `crear_pedido` | Crea un nuevo pedido | "Quiero 5 bolsas de chifles de sal" |
| `registrar_cliente` | Registra un cliente nuevo | "Registrarme como cliente nuevo" |
| `analisis_ventas` | Genera reportes de ventas | "Â¿CuÃ¡nto vendimos esta semana?" |

---

## ğŸ”„ El Ciclo Completo de una ConversaciÃ³n

Cuando envÃ­as un mensaje, pasan estas cosas:

```
1. ğŸ“¨ Tu mensaje llega al ChatController

2. ğŸ’¾ Se guarda en el historial de sesiÃ³n

3. ğŸ§  Se envÃ­a al LLM (IA) junto con:
   - Tu mensaje
   - El historial previo
   - Las herramientas disponibles
   - ImÃ¡genes (si enviaste alguna)

4. ğŸ¤” El LLM analiza y decide:
   - Si puede responder directo â†’ Responde
   - Si necesita datos â†’ Pide usar una herramienta

5. ğŸ› ï¸ Si pidiÃ³ herramientas:
   - Se ejecuta la herramienta (ej: consultar productos)
   - Se obtienen los datos del API Rest
   - Se envÃ­an los resultados al LLM

6. ğŸ“ El LLM genera la respuesta final con los datos

7. ğŸ“¤ Se te envÃ­a la respuesta
```

**Este ciclo de herramientas puede repetirse hasta 5 veces** si el asistente necesita usar varias herramientas para responder tu pregunta.

---

## âš™ï¸ ConfiguraciÃ³n

### Variables de Entorno (.env)

```env
# Puerto del servicio
PORT=3003

# Proveedor por defecto: 'gemini', 'grok', 'openai' o 'groq'
DEFAULT_LLM_PROVIDER=groq

# APIs de los proveedores (necesitas al menos una)
GROQ_API_KEY=tu-api-key-de-groq
GEMINI_API_KEY=tu-api-key-de-gemini
GROK_API_KEY=tu-api-key-de-grok
OPENAI_API_KEY=tu-api-key-de-openai

# ConexiÃ³n con otros servicios
API_REST_URL=http://localhost:3000      # API Rest de NestJS
WEBSOCKET_URL=http://localhost:8080      # Servidor WebSocket de Go
```

### Â¿DÃ³nde obtener las API Keys?

| Proveedor | URL | Costo |
|-----------|-----|-------|
| Groq | https://console.groq.com/keys | Gratis |
| Gemini | https://aistudio.google.com/app/apikey | Gratis (con lÃ­mites) |
| Grok | https://console.x.ai/ | De pago |
| OpenAI | https://platform.openai.com/api-keys | De pago |

---

## ğŸš€ CÃ³mo Ejecutar

### Desarrollo
```bash
cd ai-orchestrator
npm install
npm run start:dev
```

### ProducciÃ³n
```bash
npm run build
npm run start:prod
```

El servicio estarÃ¡ disponible en `http://localhost:3003`

---

## ğŸ“¡ Ejemplo de Uso con la API

### Enviar un mensaje simple
```bash
POST http://localhost:3003/api/chat/message
Content-Type: application/json

{
  "text": "Â¿QuÃ© productos tienen disponibles?",
  "sessionId": "mi-sesion-123"
}
```

### Respuesta
```json
{
  "text": "Â¡Hola! Tenemos estos productos disponibles:\n\n1. **Chifles de Sal** - $5.00\n2. **Chifles de LimÃ³n** - $5.50\n...",
  "toolsUsed": ["consultar_productos"],
  "sessionId": "mi-sesion-123",
  "timestamp": "2026-01-19T10:30:00.000Z",
  "model": "llama-3.3-70b-versatile",
  "provider": "Groq"
}
```

### Enviar mensaje con imagen
```bash
POST http://localhost:3003/api/chat/message
Content-Type: application/json

{
  "text": "Â¿Puedes identificar los productos en esta imagen?",
  "image": "data:image/jpeg;base64,/9j/4AAQ...",
  "sessionId": "mi-sesion-123"
}
```

---

## ğŸ—ï¸ Arquitectura del Proyecto

```
ai-orchestrator/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.ts                 # Punto de entrada de la aplicaciÃ³n
â”‚   â”œâ”€â”€ app.module.ts           # MÃ³dulo raÃ­z que une todo
â”‚   â”‚
â”‚   â”œâ”€â”€ chat/                   # ğŸ’¬ MÃ³dulo de Chat
â”‚   â”‚   â”œâ”€â”€ chat.controller.ts  # Endpoints HTTP
â”‚   â”‚   â”œâ”€â”€ chat.service.ts     # LÃ³gica de procesamiento
â”‚   â”‚   â”œâ”€â”€ dto/                # ValidaciÃ³n de datos de entrada
â”‚   â”‚   â””â”€â”€ interfaces/         # Tipos e interfaces
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/                    # ğŸ§  MÃ³dulo de IA
â”‚   â”‚   â”œâ”€â”€ llm.service.ts      # Orquestador de proveedores
â”‚   â”‚   â”œâ”€â”€ llm.module.ts       # ConfiguraciÃ³n del mÃ³dulo
â”‚   â”‚   â”œâ”€â”€ providers/          # Implementaciones de cada IA
â”‚   â”‚   â”‚   â”œâ”€â”€ gemini.provider.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ grok.provider.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ openai.provider.ts
â”‚   â”‚   â”‚   â””â”€â”€ groq.provider.ts
â”‚   â”‚   â””â”€â”€ interfaces/         # Tipos compartidos
â”‚   â”‚
â”‚   â””â”€â”€ mcp/                    # ğŸ› ï¸ MÃ³dulo de Herramientas
â”‚       â”œâ”€â”€ mcp-tools.service.ts  # Ejecutor de herramientas
â”‚       â”œâ”€â”€ mcp.module.ts         # ConfiguraciÃ³n del mÃ³dulo
â”‚       â””â”€â”€ tools/
â”‚           â””â”€â”€ tool-definitions.ts  # DefiniciÃ³n de herramientas
â”‚
â”œâ”€â”€ .env                        # Variables de entorno
â”œâ”€â”€ package.json                # Dependencias
â””â”€â”€ tsconfig.json               # ConfiguraciÃ³n TypeScript
```

---

## ğŸ”Œ IntegraciÃ³n con Otros Servicios

El AI Orchestrator se conecta con:

1. **API Rest (NestJS)** - Puerto 3000
   - Para consultar/crear productos, pedidos, clientes
   - Todas las operaciones CRUD del sistema

2. **WebSocket Server (Go)** - Puerto 8080
   - Para enviar notificaciones en tiempo real
   - Cuando se crea un pedido, notifica al frontend

3. **Frontend (Next.js)** - Puerto 3002
   - El chat del frontend se comunica con este servicio
   - CORS configurado para permitir conexiones

---

## ğŸ“ Resumen para Entender RÃ¡pido

1. **Es un chatbot inteligente** que entiende espaÃ±ol y puede hacer acciones reales
2. **Usa IA de verdad** (Groq, Gemini, GPT, etc.) para entender lo que escribes
3. **Tiene herramientas** para consultar productos, crear pedidos, ver reportes
4. **Mantiene contexto** - recuerda lo que hablaste en la sesiÃ³n
5. **Se integra** con el API Rest y el WebSocket del sistema
6. **Es configurable** - puedes cambiar de IA en cualquier momento

---

## ğŸ“š TecnologÃ­as Usadas

- **NestJS** - Framework de Node.js para el backend
- **TypeScript** - JavaScript con tipos para mayor seguridad
- **@google/generative-ai** - SDK de Google Gemini
- **Axios** - Cliente HTTP para llamadas a APIs externas
- **class-validator** - ValidaciÃ³n de datos de entrada
- **uuid** - GeneraciÃ³n de IDs Ãºnicos para sesiones

---

## ğŸ› SoluciÃ³n de Problemas Comunes

### "Error: GEMINI_API_KEY no estÃ¡ configurada"
â¡ï¸ Agrega tu API key en el archivo `.env`

### "Cuota de API excedida"
â¡ï¸ El servicio maneja esto automÃ¡ticamente y te avisa. Espera unos segundos o cambia de proveedor.

### "Herramienta desconocida"
â¡ï¸ El LLM intentÃ³ usar una herramienta que no existe. Esto no deberÃ­a pasar, pero si pasa, revisa los logs.

### "Error al consultar productos"
â¡ï¸ Verifica que el API Rest estÃ© corriendo en el puerto 3000

---

Â¡Listo! Ahora entiendes cÃ³mo funciona el AI Orchestrator. Si tienes dudas, simplemente pregÃºntale al asistente ğŸ˜„
