# Gu√≠a de Implementaci√≥n Paso a Paso - Punto 3 (IA, MCP y Frontend)

Esta gu√≠a detalla los pasos necesarios para implementar la arquitectura de AI Orchestrator, servidor MCP, herramientas multimodales y las extensiones del frontend para el Sistema Chifles.

## üèõÔ∏è Arquitectura Propuesta

```mermaid
graph TD
    User[Usuario] -->|Interact√∫a| FE[Frontend Next.js]
    FE -->|WebSocket| WS[Go WebSocket Server]
    FE -->|HTTP| API[Api-Rest NestJS]
    FE -->|HTTP - Chat/Multimodal| AI[AI Orchestrator NestJS]
    
    AI -->|Usa| LLM[LLM Adapter Strategy]
    LLM -->|API| Gemini[Gemini API]
    LLM -->|API| OpenAI[OpenAI API]
    
    AI -->|MCP Protocol| MCP[MCP Server Tools]
    MCP -->|Consulta/Acci√≥n| API
    
    API -->|Persistencia| DB[(PostgreSQL)]
    AI -->|Notificaci√≥n| WS
```

---

## üöÄ Fase 1: Crear el AI Orchestrator (Backend)

El Orchestrator ser√° un nuevo microservicio (o un m√≥dulo independiente) encargado de procesar el lenguaje natural y ejecutar herramientas. Recomendamos crearlo como un nuevo proyecto NestJS para mantener consistencia.

### Paso 1.1: Inicializaci√≥n
En la ra√≠z del workspace:
```bash
nest new ai-orchestrator
cd ai-orchestrator
npm install @nestjs/config @nestjs/axios axios class-validator class-transformer
```

### Paso 1.2: Implementar el LLM Adapter (Patr√≥n Strategy)
Necesitas una abstracci√≥n para cambiar entre proveedores (Gemini/OpenAI).

**Archivo:** `src/llm/interfaces/llm-provider.interface.ts`
```typescript
export interface LLMResponse {
  text: string;
  toolCalls?: any[]; // Si el modelo solicita ejecutar una herramienta
}

export interface LLMProvider {
  generateResponse(prompt: string, images?: string[], history?: any[]): Promise<LLMResponse>;
}
```

**Archivo:** `src/llm/providers/gemini.provider.ts`
```typescript
import { Injectable } from '@nestjs/common';
import { LLMProvider, LLMResponse } from '../interfaces/llm-provider.interface';
import { GoogleGenerativeAI } from '@google/generative-ai';

@Injectable()
export class GeminiProvider implements LLMProvider {
  private genAI: GoogleGenerativeAI;
  private model: any;

  constructor() {
    this.genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
    this.model = this.genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
  }

  async generateResponse(prompt: string, images: string[] = [], history: any[] = []): Promise<LLMResponse> {
    // L√≥gica para convertir im√°genes base64 a formato de Gemini
    // L√≥gica para enviar prompt y retornar respuesta
    return { text: "Respuesta simulada de Gemini" };
  }
}
```

### Paso 1.3: Configurar MCP Server y Tools
Aqu√≠ definimos las herramientas que la IA puede usar. Estas herramientas har√°n llamadas HTTP a tu `Api-Rest` existente.

**Estructura de las 5 Herramientas M√≠nimas:**

1.  **Consulta - `consultar_productos`**:
    *   *Descripci√≥n*: Obtiene la lista de chifles/productos disponibles y su precio.
    *   *Acci√≥n*: `GET http://localhost:3000/productos` (API Rest).
2.  **Consulta - `estado_pedido`**:
    *   *Descripci√≥n*: Dado un ID, verifica el estado.
    *   *Acci√≥n*: `GET http://localhost:3000/pedidos/:id`.
3.  **Acci√≥n - `crear_pedido`**:
    *   *Descripci√≥n*: Crea un nuevo pedido con lista de items.
    *   *Acci√≥n*: `POST http://localhost:3000/pedidos`.
4.  **Acci√≥n - `registrar_reclamo`** (o Cliente):
    *   *Descripci√≥n*: Registra un issue o crea un cliente.
    *   *Acci√≥n*: `POST http://localhost:3000/clientes`.
5.  **Reporte - `analisis_ventas`**:
    *   *Descripci√≥n*: Genera un resumen de ventas.
    *   *Acci√≥n*: L√≥gica interna que consulta varios endpoints y resume.

**Implementaci√≥n en el Orchestrator:**
Crea un servicio `McpToolsService` que contenga m√©todos para cada una de estas acciones usando `HttpService` (axios).

### Paso 1.4: Entradas Multimodales (Endpoint Principal)
Crea un controlador `ChatController` en el AI Orchestrator.

```typescript
@Post('message')
async handleMessage(@Body() body: ChatDto) {
  // body.text: Texto del usuario
  // body.image: Imagen en Base64 (Opcional)
  // 1. Guardar log de interacci√≥n (Entrada)
  // 2. Llamar al LLM Provider seleccionado
  // 3. Si el LLM decide usar una tool -> Ejecutar MCP Tool -> Volver a llamar LLM con el resultado
  // 4. Guardar log de interacci√≥n (Salida)
  // 5. Retornar respuesta final
}
```

---

## üíª Fase 2: Frontend (Extender Primer Parcial)

### Paso 2.1: Nueva P√°gina de Chat
En `frontend/src/app/chat/page.tsx`:
*   Crear una interfaz tipo WhatsApp/ChatGPT.
*   **Input de Texto**: Campo obligatorio.
*   **Bot√≥n de Upload**: Para subir im√°genes (PDF/JPG).
    *   *Nota*: Convertir el archivo a Base64 antes de enviarlo al AI Orchestrator.

### Paso 2.2: Logs de Interacciones
Mostrar en el chat el historial de la conversaci√≥n. Este historial debe venir del estado del frontend o persistirse en el backend si se requiere historial entre sesiones.

### Paso 2.3: M√≥dulo de Pagos
Agregar una pantalla o modal simple de pagos.
*   Puede ser en `frontend/src/app/pagos/page.tsx`.
*   Integrar con el flujo de "Crear Pedido". Si el chatbot crea un pedido, puede devolver un link directo a esta p√°gina de pagos con el `monto` pre-cargado.

### Paso 2.4: Notificaciones WebSocket
El frontend ya tiene `socket.io-client`. Aseg√∫rate de escuchar eventos globales.
*   Cuando el AI Orchestrator realiza una acci√≥n (ej. "Pedido Creado"), debe enviar una petici√≥n al servidor WebSocket Go (`POST /notify`).
*   El servidor Go emitir√° el evento a los clientes conectados.
*   El frontend mostrar√° un `Toast` o alerta.

---

## üîó Fase 3: Integraci√≥n y Flujo

1.  **Auth**: Aseg√∫rate de que el request al AI Orchestrator lleve el token JWT del usuario (si es necesario saber qui√©n hace el pedido).
2.  **Orquestaci√≥n**:
    *   El usuario env√≠a foto de una factura o lista manuscrita de pedido.
    *   El **LLM** (Gemini) analiza la imagen y extrae los √≠tems ("3 chifles de sal, 2 de dulce").
    *   El **LLM** decide llamar a la tool `crear_pedido`.
    *   El **AI Orchestrator** ejecuta la tool -> llama a `Api-Rest`.
    *   `Api-Rest` guarda en Postgres.
    *   **AI Orchestrator** llama a `Websocket Server` -> "Nuevo pedido creado via IA".
    *   Frontend recibe notificaci√≥n y actualiza la vista.

## üìù Documentaci√≥n Requerida

Crea un archivo `AI_MCP_DOCS.md` donde documentes:
*   La definici√≥n JSON de tus 5 tools.
*   Diagrama de secuencia del flujo del Chatbot.
*   Evidencia de las pruebas con im√°genes (multimodal).

---

## ‚úÖ Checklist de Entrega

- [ ] AI Orchestrator corriendo (Puerto ej. 3001).
- [ ] Conexi√≥n a Gemini/OpenAI funcionando.
- [ ] 5 Tools MCP implementadas y probadas.
- [ ] Frontend con Chat UI y subida de archivos.
- [ ] Notificaciones WebSocket llegando al frontend.
- [ ] Documentaci√≥n t√©cnica completada.
